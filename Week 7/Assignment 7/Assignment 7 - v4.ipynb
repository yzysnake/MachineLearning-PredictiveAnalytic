{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b857433c-e0f9-4939-90a2-936db5051fe3",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-10T03:45:26.045379Z",
     "start_time": "2024-05-10T03:45:26.038380Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee041e5cfdcaf711"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "417f9968-b05a-407d-a5ff-3d9622f282b2",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-10T03:44:34.537780Z",
     "start_time": "2024-05-10T03:44:34.514780Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = pd.read_csv('train_sample.csv')\n",
    "test_data = pd.read_csv('test_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dda730f-413f-4aa8-a427-1e46f240f171",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-10T03:44:35.240169Z",
     "start_time": "2024-05-10T03:44:35.225162Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "X = train_data[['feature_0', 'feature_1', 'feature_2']].values\n",
    "y = train_data['target'].values\n",
    "X_test = test_data[['feature_0', 'feature_1', 'feature_2']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0fbe0c8-32f5-4c47-81a0-9040f57ed733",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-10T03:44:36.114376Z",
     "start_time": "2024-05-10T03:44:36.100368Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f901aa4-5b04-4d57-a655-08a25985ccdc",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-10T03:44:36.739348Z",
     "start_time": "2024-05-10T03:44:36.730340Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_features = X_train.shape[1]\n",
    "latent_factors = 10\n",
    "batch_size = 32\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae139b7-f902-4ad1-8da2-e7eac0684d8b",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f396085-3c8d-494a-9e56-99f21a34f6a5",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-10T03:47:02.379563Z",
     "start_time": "2024-05-10T03:47:02.329057Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# More complex model\n",
    "inputs = [Input(shape=(1,)) for _ in range(n_features)]\n",
    "embeddings = [Embedding(input_dim=np.max(X_train[:, i])+1, output_dim=20)(inputs[i]) for i in range(n_features)]\n",
    "flat_embeddings = [Flatten()(embed) for embed in embeddings]\n",
    "concat = concatenate(flat_embeddings)\n",
    "dense = Dense(50, activation='relu', kernel_regularizer=l2(0.01))(concat)\n",
    "dropout = Dropout(0.5)(dense)\n",
    "outputs = Dense(1)(dropout)\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Optimizer with a different learning rate\n",
    "optimizer = Adam(clipnorm=1.0, learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Define the early stopping callback\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dc53790-eaaf-4adc-92c8-7b0c8d6248e9",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-10T03:47:16.950048Z",
     "start_time": "2024-05-10T03:47:02.910834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "225/225 [==============================] - 2s 4ms/step - loss: 0.6163 - val_loss: 0.2199\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.2037 - val_loss: 0.1539\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.1713 - val_loss: 0.1383\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1608 - val_loss: 0.1325\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1504 - val_loss: 0.1275\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1506 - val_loss: 0.1281\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.1417 - val_loss: 0.1240\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1426 - val_loss: 0.1255\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1406 - val_loss: 0.1241\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1412 - val_loss: 0.1194\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1383 - val_loss: 0.1204\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1400 - val_loss: 0.1179\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1403 - val_loss: 0.1188\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1404 - val_loss: 0.1207\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1400 - val_loss: 0.1238\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1365 - val_loss: 0.1241\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1375 - val_loss: 0.1206\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x245f5a46670>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model with early stopping\n",
    "model.fit([X_train[:, i] for i in range(n_features)], y_train, epochs=n_epochs, batch_size=batch_size, verbose=1,\n",
    "          validation_data=([X_val[:, i] for i in range(n_features)], y_val), callbacks=[earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dc35983-6554-4719-b410-da5f1e7733b0",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-10T03:54:47.779586Z",
     "start_time": "2024-05-10T03:54:34.131993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1439\n",
      "Epoch 2/15\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1404\n",
      "Epoch 3/15\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1397\n",
      "Epoch 4/15\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1414\n",
      "Epoch 5/15\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1354\n",
      "Epoch 6/15\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1376\n",
      "Epoch 7/15\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1381\n",
      "Epoch 8/15\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1382\n",
      "Epoch 9/15\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1366\n",
      "Epoch 10/15\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1361\n",
      "Epoch 11/15\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1386\n",
      "Epoch 12/15\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1418\n",
      "Epoch 13/15\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1369\n",
      "Epoch 14/15\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1383\n",
      "Epoch 15/15\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1363\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x245f6673550>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit the model to the entire dataset\n",
    "best_epoch = earlystopper.stopped_epoch - 1 if earlystopper.stopped_epoch > 0 else n_epochs\n",
    "model.fit([X[:, i] for i in range(n_features)], y, epochs=best_epoch, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e90465-20f1-475f-acf2-b63dcab830b4",
   "metadata": {},
   "source": [
    "### v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0f83396-1cf8-4ffe-a8f6-1fc629c3813b",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-10T04:18:06.968689Z",
     "start_time": "2024-05-10T04:03:09.402387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 3 latent factors, clipnorm=0.5, L2 reg=0.0001\n",
      "Validation RMSE: 0.3296\n",
      "INFO:tensorflow:Assets written to: best_model\\assets\n",
      "Training model with 3 latent factors, clipnorm=0.5, L2 reg=0.0005\n",
      "Validation RMSE: 0.2644\n",
      "INFO:tensorflow:Assets written to: best_model\\assets\n",
      "Training model with 3 latent factors, clipnorm=0.5, L2 reg=0.0008\n",
      "Validation RMSE: 0.3386\n",
      "Training model with 3 latent factors, clipnorm=1.0, L2 reg=0.0001\n",
      "Validation RMSE: 0.2646\n",
      "Training model with 3 latent factors, clipnorm=1.0, L2 reg=0.0005\n",
      "Validation RMSE: 0.2755\n",
      "Training model with 3 latent factors, clipnorm=1.0, L2 reg=0.0008\n",
      "Validation RMSE: 0.2628\n",
      "INFO:tensorflow:Assets written to: best_model\\assets\n",
      "Training model with 3 latent factors, clipnorm=1.5, L2 reg=0.0001\n",
      "Validation RMSE: 0.2720\n",
      "Training model with 3 latent factors, clipnorm=1.5, L2 reg=0.0005\n",
      "Validation RMSE: 0.2628\n",
      "INFO:tensorflow:Assets written to: best_model\\assets\n",
      "Training model with 3 latent factors, clipnorm=1.5, L2 reg=0.0008\n",
      "Validation RMSE: 0.2661\n",
      "Training model with 5 latent factors, clipnorm=0.5, L2 reg=0.0001\n",
      "Validation RMSE: 0.2686\n",
      "Training model with 5 latent factors, clipnorm=0.5, L2 reg=0.0005\n",
      "Validation RMSE: 0.2350\n",
      "INFO:tensorflow:Assets written to: best_model\\assets\n",
      "Training model with 5 latent factors, clipnorm=0.5, L2 reg=0.0008\n",
      "Validation RMSE: 0.2376\n",
      "Training model with 5 latent factors, clipnorm=1.0, L2 reg=0.0001\n",
      "Validation RMSE: 0.2304\n",
      "INFO:tensorflow:Assets written to: best_model\\assets\n",
      "Training model with 5 latent factors, clipnorm=1.0, L2 reg=0.0005\n",
      "Validation RMSE: 0.2310\n",
      "Training model with 5 latent factors, clipnorm=1.0, L2 reg=0.0008\n",
      "Validation RMSE: 0.3285\n",
      "Training model with 5 latent factors, clipnorm=1.5, L2 reg=0.0001\n",
      "Validation RMSE: 0.2311\n",
      "Training model with 5 latent factors, clipnorm=1.5, L2 reg=0.0005\n",
      "Validation RMSE: 0.2241\n",
      "INFO:tensorflow:Assets written to: best_model\\assets\n",
      "Training model with 5 latent factors, clipnorm=1.5, L2 reg=0.0008\n",
      "Validation RMSE: 0.3325\n",
      "Training model with 3 latent factors, clipnorm=0.5, L2 reg=0.0001\n",
      "Validation RMSE: 0.2370\n",
      "Training model with 3 latent factors, clipnorm=0.5, L2 reg=0.0005\n",
      "Validation RMSE: 0.2419\n",
      "Training model with 3 latent factors, clipnorm=0.5, L2 reg=0.0008\n",
      "Validation RMSE: 0.2364\n",
      "Training model with 3 latent factors, clipnorm=1.0, L2 reg=0.0001\n",
      "Validation RMSE: 0.2698\n",
      "Training model with 3 latent factors, clipnorm=1.0, L2 reg=0.0005\n",
      "Validation RMSE: 0.3420\n",
      "Training model with 3 latent factors, clipnorm=1.0, L2 reg=0.0008\n",
      "Validation RMSE: 0.3561\n",
      "Training model with 3 latent factors, clipnorm=1.5, L2 reg=0.0001\n",
      "Validation RMSE: 0.3532\n",
      "Training model with 3 latent factors, clipnorm=1.5, L2 reg=0.0005\n",
      "Validation RMSE: 0.2702\n",
      "Training model with 3 latent factors, clipnorm=1.5, L2 reg=0.0008\n",
      "Validation RMSE: 0.3447\n",
      "Training model with 5 latent factors, clipnorm=0.5, L2 reg=0.0001\n",
      "Validation RMSE: 0.2336\n",
      "Training model with 5 latent factors, clipnorm=0.5, L2 reg=0.0005\n",
      "Validation RMSE: 0.3438\n",
      "Training model with 5 latent factors, clipnorm=0.5, L2 reg=0.0008\n",
      "Validation RMSE: 0.3477\n",
      "Training model with 5 latent factors, clipnorm=1.0, L2 reg=0.0001\n",
      "Validation RMSE: 0.2649\n",
      "Training model with 5 latent factors, clipnorm=1.0, L2 reg=0.0005\n",
      "Validation RMSE: 0.3454\n",
      "Training model with 5 latent factors, clipnorm=1.0, L2 reg=0.0008\n",
      "Validation RMSE: 0.2724\n",
      "Training model with 5 latent factors, clipnorm=1.5, L2 reg=0.0001\n",
      "Validation RMSE: 0.2719\n",
      "Training model with 5 latent factors, clipnorm=1.5, L2 reg=0.0005\n",
      "Validation RMSE: 0.2537\n",
      "Training model with 5 latent factors, clipnorm=1.5, L2 reg=0.0008\n",
      "Validation RMSE: 0.3523\n",
      "Training model with 3 latent factors, clipnorm=0.5, L2 reg=0.0001\n",
      "Validation RMSE: 0.3406\n",
      "Training model with 3 latent factors, clipnorm=0.5, L2 reg=0.0005\n",
      "Validation RMSE: 0.2780\n",
      "Training model with 3 latent factors, clipnorm=0.5, L2 reg=0.0008\n",
      "Validation RMSE: 0.3398\n",
      "Training model with 3 latent factors, clipnorm=1.0, L2 reg=0.0001\n",
      "Validation RMSE: 0.2514\n",
      "Training model with 3 latent factors, clipnorm=1.0, L2 reg=0.0005\n",
      "Validation RMSE: 0.3389\n",
      "Training model with 3 latent factors, clipnorm=1.0, L2 reg=0.0008\n",
      "Validation RMSE: 0.2787\n",
      "Training model with 3 latent factors, clipnorm=1.5, L2 reg=0.0001\n",
      "Validation RMSE: 0.3358\n",
      "Training model with 3 latent factors, clipnorm=1.5, L2 reg=0.0005\n",
      "Validation RMSE: 0.3505\n",
      "Training model with 3 latent factors, clipnorm=1.5, L2 reg=0.0008\n",
      "Validation RMSE: 0.2766\n",
      "Training model with 5 latent factors, clipnorm=0.5, L2 reg=0.0001\n",
      "Validation RMSE: 0.2799\n",
      "Training model with 5 latent factors, clipnorm=0.5, L2 reg=0.0005\n",
      "Validation RMSE: 0.3387\n",
      "Training model with 5 latent factors, clipnorm=0.5, L2 reg=0.0008\n",
      "Validation RMSE: 0.2834\n",
      "Training model with 5 latent factors, clipnorm=1.0, L2 reg=0.0001\n",
      "Validation RMSE: 0.2448\n",
      "Training model with 5 latent factors, clipnorm=1.0, L2 reg=0.0005\n",
      "Validation RMSE: 0.2525\n",
      "Training model with 5 latent factors, clipnorm=1.0, L2 reg=0.0008\n",
      "Validation RMSE: 0.2836\n",
      "Training model with 5 latent factors, clipnorm=1.5, L2 reg=0.0001\n",
      "Validation RMSE: 0.3369\n",
      "Training model with 5 latent factors, clipnorm=1.5, L2 reg=0.0005\n",
      "Validation RMSE: 0.2436\n",
      "Training model with 5 latent factors, clipnorm=1.5, L2 reg=0.0008\n",
      "Validation RMSE: 0.3391\n",
      "Training model with 3 latent factors, clipnorm=0.5, L2 reg=0.0001\n",
      "Validation RMSE: 0.2896\n",
      "Training model with 3 latent factors, clipnorm=0.5, L2 reg=0.0005\n",
      "Validation RMSE: 0.3332\n",
      "Training model with 3 latent factors, clipnorm=0.5, L2 reg=0.0008\n",
      "Validation RMSE: 0.2916\n",
      "Training model with 3 latent factors, clipnorm=1.0, L2 reg=0.0001\n",
      "Validation RMSE: 0.2712\n",
      "Training model with 3 latent factors, clipnorm=1.0, L2 reg=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, concatenate, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from math import sqrt\n",
    "\n",
    "# Function to create and compile a model\n",
    "def create_model(latent_dim, clipnorm, reg_lambda):\n",
    "    inputs = [Input(shape=(1,)) for _ in range(n_features)]\n",
    "    embeddings = [Embedding(input_dim=np.max(X_train[:, i])+1, output_dim=latent_dim, embeddings_regularizer=l2(reg_lambda))(inputs[i]) for i in range(n_features)]\n",
    "    flat_embeddings = [Flatten()(embed) for embed in embeddings]\n",
    "    concat = concatenate(flat_embeddings)\n",
    "    dense1 = Dense(100, activation='relu')(concat)\n",
    "    batch_norm1 = BatchNormalization()(dense1)\n",
    "    # dropout1 = Dropout(0.3)(batch_norm1)\n",
    "    dense2 = Dense(50, activation='relu')(batch_norm1)\n",
    "    batch_norm2 = BatchNormalization()(dense2)\n",
    "    # dropout2 = Dropout(0.2)(batch_norm2)\n",
    "    outputs = Dense(1)(batch_norm2)\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    # Compile model with a refined optimizer\n",
    "    optimizer = Adam(learning_rate=0.001, clipnorm=clipnorm)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model\n",
    "\n",
    "# Load data here (omitted for brevity, assume X_train, y_train, X_test are loaded and prepared)\n",
    "# Assume n_features is set based on your dataset\n",
    "\n",
    "# Grid of hyperparameters\n",
    "latent_dims = [3, 5]\n",
    "clipnorms = [0.5, 1.0, 1.5]\n",
    "reg_lambdas = [0.0001, 0.0005, 0.0008]\n",
    "\n",
    "best_score = float('inf')\n",
    "best_model = None\n",
    "\n",
    "# K-fold cross-validation\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_kf, X_val_kf = X_train[train_index], X_train[val_index]\n",
    "    y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    for latent_dim in latent_dims:\n",
    "        for clipnorm in clipnorms:\n",
    "            for reg_lambda in reg_lambdas:\n",
    "                print(f\"Training model with {latent_dim} latent factors, clipnorm={clipnorm}, L2 reg={reg_lambda}\")\n",
    "                model = create_model(latent_dim, clipnorm, reg_lambda)\n",
    "                early_stopper = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "                model.fit([X_train_kf[:, i] for i in range(n_features)], y_train_kf, epochs=50, batch_size=32, verbose=0,\n",
    "                          validation_data=([X_val_kf[:, i] for i in range(n_features)], y_val_kf), callbacks=[early_stopper])\n",
    "                val_loss = model.evaluate([X_val_kf[:, i] for i in range(n_features)], y_val_kf, verbose=0)\n",
    "                val_rmse = sqrt(val_loss)\n",
    "                print(f\"Validation RMSE: {val_rmse:.4f}\")\n",
    "                \n",
    "                if val_loss < best_score:\n",
    "                    best_score = val_loss\n",
    "                    best_model = model\n",
    "                    # Save best model\n",
    "                    model.save('best_model', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_model(latent_dim, clipnorm, reg_lambda):\n",
    "    inputs = [Input(shape=(1,)) for _ in range(n_features)]\n",
    "    embeddings = [Embedding(input_dim=np.max(X_train[:, i])+1, output_dim=latent_dim, embeddings_regularizer=l2(reg_lambda))(inputs[i]) for i in range(n_features)]\n",
    "    flat_embeddings = [Flatten()(embed) for embed in embeddings]\n",
    "    concat = concatenate(flat_embeddings)\n",
    "    dense1 = Dense(200, activation='relu')(concat)\n",
    "    batch_norm1 = BatchNormalization()(dense1)\n",
    "    dropout1 = Dropout(0.3)(batch_norm1)\n",
    "    dense2 = Dense(100, activation='relu')(dropout1)\n",
    "    batch_norm2 = BatchNormalization()(dense2)\n",
    "    dropout2 = Dropout(0.2)(batch_norm2)\n",
    "    outputs = Dense(1)(dropout2)\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    # Compile model with a refined optimizer\n",
    "    optimizer = Adam(learning_rate=0.001, clipnorm=clipnorm)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T04:27:12.524771Z",
     "start_time": "2024-05-10T04:27:12.514780Z"
    }
   },
   "id": "6ee5cc9b0704565d",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = create_model(5, 1.5, 0.0001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T04:27:12.987475Z",
     "start_time": "2024-05-10T04:27:12.921467Z"
    }
   },
   "id": "2d0b1997f4803c6c",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bea53bb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T04:27:24.384580Z",
     "start_time": "2024-05-10T04:27:13.303052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.2311\n"
     ]
    }
   ],
   "source": [
    "model.fit([X_train_kf[:, i] for i in range(n_features)], y_train_kf, epochs=300, batch_size=128, verbose=0,\n",
    "validation_data=([X_val_kf[:, i] for i in range(n_features)], y_val_kf), callbacks=[early_stopper])\n",
    "val_loss = model.evaluate([X_val_kf[:, i] for i in range(n_features)], y_val_kf, verbose=0)\n",
    "val_rmse = sqrt(val_loss)\n",
    "print(f\"Validation RMSE: {val_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d557c43c-2df0-42fd-ad25-ce835339bb88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T04:27:30.944443Z",
     "start_time": "2024-05-10T04:27:30.735372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict and average predictions if multiple folds/models are used\n",
    "predictions = model.predict([X_test[:, i] for i in range(n_features)])\n",
    "# Implement averaging if using multiple models from different folds or configurations\n",
    "\n",
    "# Save predictions\n",
    "sub = pd.DataFrame({'ID': test_data['ID'], 'target': predictions.flatten()})\n",
    "sub.to_csv('submission3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8c739a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m119"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
